<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
  <title>Elsa Design</title>
  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
  <style type="text/css">
    H1 { font-size: 150% }
    H2 { font-size: 125% }
    H3 { font-size: 100% }
    P.title { font-size: 175% }
    P.remark { font-size: 125%; color: red }
    SPAN.todo { font-weight: bold }
  </style>
</head>
<body>

<center>
<p class="title"><b>Elsa Design</b></p>
<p class="remark">Initial Outline</p>
<p>By Daniel Wilkerson and Scott McPeak
</center>

<h1>Introduction</h1>

<p>This file is an attempt to articulate the design of
<a href="index.html">Elsa</a>
to someone who would like to work on it.

<p>The goals of Elsa are as follows.
<ul>

<li>Implement the C++98 spec, more formally known as "ISO/IEC
14882:1998: Programming languages -- C++."  You will see it refereed to
as "cppstd" in comments throughout the code.

<li>Parse C; that is C89 and C99. <span class="todo">Give spec names</span>

<li>Parse C and C++ as the are in the wild, including K&amp;R "Old
Style" C, and Gcc.

</ul>

<p>To accommodate the multiple goals, Elsa is extensible; that is one
may arrange one's build process to build Elsa and incorporate
extensions to lexing, parsing, and to some extent typechecking without
modifying the original Elsa distribution files.  This
"base-and-extension design pattern" occurs frequently in the Elsa
build process.  Support for C99 and GNU extensions to C++
are implemented within Elsa using these extension mechanisms.

<p>Processing of an input file proceeds in the following three stages.
<ol>
<li><a href="#lexing">Lexing</a>
<li><a href="#parsing">Parsing</a>
<li><a href="#typechecking">Typechecking</a>
<li><a href="#elaboration_cdtors">elaboration</a> (of constructors and destructors)
</ol>

<a name="lexing"></a>
<h1>1. Lexing</h1>

<p><center><img src="lexer_build.png"></center>

<p><a href="cc.lex"><tt>cc.lex</tt></a> is the base lexer file written in flex.  
To extend Elsa one may write a file containing a flex lexer fragment, and have 
it merged into cc.lex by
<a href="merge-lexer-exts.pl">merge-lexer-exts.pl</a>
to produce
<a href="lexer.lex">lexer.lex</a>;
<a href="gnu.lex">gnu.lex</a>
is one such
lexer extension file used to add the lexing of gnu and C99 token extensions.

<p><tt>lexer.lex</tt> is subsequently compiled into
lexer.yy.cc by
<a href="http://www.gnu.org/software/flex/manual/html_chapter/flex_toc.html">flex</a>;
note that we make flex generate a C++ lexer.

<p>Multiple parts of the system need to know various properties of the
tokens that the lexer may produce. 

<ol>
<li>
<a href="cc_tokens.h">cc_tokens.h</a>
is a header file suitable for inclusion into a C++
file.  Among other things it contains
  <ol>

  <li>an <tt>enum TokenType</tt> with <tt>TOK_*</tt> token for every token,

  <li>declares an array of strings <tt>tokenNameTable</tt> that maps every
  token to a canonical string for human reading,

  <li>and an array of TokenFlags <tt>tokenFlagTable</tt> attaching some boolean
  properties to each token.

  </ol>

<li><a href="cc_tokens.cc">cc_tokens.cc</a> that defines <tt>tokenNameTable</tt> 
and <tt>tokenFlagTable</tt>
and computes automatically the <tt>tokenNameTableSize</tt>.

<li><a href="cc_tokens.ids">cc_tokens.ids</a> <b>Who reads this file and why and how come I can't find it in the build process?</b>
</ol>

<p>These three files share partly redundant information and so they
are all generated by <a href="../elkhound/make-token-files">elkhound/make-token-files</a> 
from ".tok" files; The
language is so simple that the base <a href="cc_tokens.tok">cc_tokens.tok</a>
and any extension
".tok" files can simply be all passed in at once or concatenated
first.

<a name="parsing"></a>
<h1>2. Parsing</h1>

<h2>2.1 Parsing: grammar</h2>

<p>The Elsa parser is written in <a href="../elkhound/index.html">elkhound</a>.
Elkhound is a language
reminiscent of yacc/bison and with the same purpose: to allow the
client to declaratively describe a grammar with user actions at each
parsing stage and have a parser for that grammar which executes those
user actions generated automatically.  Elkhound is different in that
it allows ambiguous grammars; it uses the GLR algorithm to handle
this.  Elkhound was written and is maintained by Scott McPeak.

<p>The elkhound source files in Elsa end in ".gr".  The base file is
<a href="cc.gr">cc.gr</a> which is meant to be a manifestation of strict C++ 98.  The
extension files for gcc are in <a href="gnu.gr">gnu.gr</a>.  If your favorite editor has
a C++ mode it is likely to work well for ".gr" files.

<p><b>How much about elkhound should go here and how much in a similar
file for users of elkhound that should probably be in the elkhound
tree?  Need to educate the user about verbatim sections, merge, dup
and del actions, how to detect when ambiguity has exploded, how
precedence is represented.  sm: see elkhound/index.html, linked above</b>

<p>There are times when the GLR algorithm cannot resolve all ambiguity
itself within the parser, but instead comes up with two valid parses
of a substring of the input.  This results in calling the "merge"
action on a non-terminal.  This merge action can do anything, but in
Elsa it always simply appends one subtree onto the 'ambiguity'
linked-list of the other.  These ambiguities will be resolved during
the typechecking phase.

<h2>2.2 Parsing: Abstract Syntax Tree</h2>

<p>You will notice that most of the rules in the parsing user actions
make Abstract Syntax Tree (AST) nodes on the heap; the general pattern
is that they<ol>

<li>call a constructor for an AST node that represents the semantic
value of the nonterminal of the action, 

<li>pass the semantic values of the terminals and non-terminals that
caused the rule to fire as the arguments to the constructor where they
generally become filed away as fields of the object being constructed,
and

<li>return this newly constructed AST node as the semantic value of
the nonterminal of the rule.

</ol>

<p>The AST classes so constructed are rather tedious to write as
traditional C++, as one soon discovers upon attempting it.  In Elsa
they are built in Elsa using Scott McPeak's AST description language
generator called <a href="../ast/index.html">astgen</a>; the input files are named ".ast".  If your
favorite editor has a C++ mode it is likely to work well for ".ast"
files as well.

<p>The base C++ AST is defined in 
<a href="cc.ast">cc.ast</a>
(and the gnu extension is
in <a href="gnu.ast">gnu.ast</a>) and is <a href="cc.ast.html">documented separately</a>.
<b>Talk about how .ast files merge together, how the argument lists
concatenate and hierarchies merge, the purpose of each .ast file in
Elsa, such as how typechecking concerns are factored from raw parsing
concerns; warn the user of the screwy feature that you can leave out
the pointer and that is still legal and also means something else,
point out how it will only generate a 2-level deep hierarchy.</b>

<P> Tracing flag "printAST" will print the (possibly ambiguous) AST
before type checking.

<a name="typechecking"></a>
<h1>3. Typechecking</h1>

<p>The typechecking phase accomplishes five semantically independent
results.

<p><b>Type annotation</b>: Some objects, such as expressions, have
a well-defined type associated with them.  After typechecking, these
objects have been annotated with type objects.  Type objects are
declared in <a href="cc_type.h">cc_type.h</a> and are
<a href="cc_type.html">documented
separately</a>.  <b>The notion of identity for types is quite messy
and subtle; mention that the type factory may be overloaded</b>.  The
tracing flag "env" will print typechecking environment modifications as
they happen.

<p><b>Variable resolution</b>: Identifiers name a variable.  This
is how different parts of a file may refer to the same thing;
therefore all occurrences of a variable mean to refer to the same thing
are all annotated with a pointer to the same Variable object.

<p><b>Disambiguation</b>: As was mentioned in the parsing section,
the parse may be ambiguous: certain classes AST nodes have a linked
list of alternative parses.  One of these must be chosen; the general
strategy is to typecheck all of them and keep the one that results in
no errors.  It should not be possible for more than one to typecheck
and it is simply a user error if none of them typecheck.  Much of this
is generic <b>Describe generic ambiguity resolution</b>.  Some of it
is special-cased for efficiency of common ambiguities that tend to
cause an exponential blowup <b>mention function call / ctor call
ambiguity</b>.  The tracing flag "disamb" will print disambiguation
activity as it occurs.  The tracing flag "mustBeUnambiguous" will
cause Elsa to verify after type checking that the AST to verify there
are no remaining ambiguities and if there are, abort.

<p><b> There is a fifth thing but I can't remember what it is; it
goes here.</b>

<p><b>Elaboration</b>: Unlike in C, in C++, much syntax is implied. 

<ul>

<li> Operator overloading: What look like simple built-in operators
may in fact be function calls.

<li> <b>What the heck else?</b>

</ul>

<p>The tracing flag "printTypedAST" will print the AST after type
checking.


<a name="elaboration_cdtors"></a>
<h1>4. Elaboration of constructors and destructors</h1>

Constructors and destructors: 
<ul>

<li> A struct/class with no ctor gets a no arg ctor that calls the no
arg ctor of its members and superclasses.

<li> A struct/class with no copy ctor gets a one arg copy ctor that
calls the copy ctor for its members and superclasses.

<li> A struct/class with no copy assignment operator gets a one arg
copy assignment operator that calls the copy assignment operator for
its members and superclasses.

<li> A struct/class with no dtor gets a dtor that calls the dtor for
its members and superclasses.

</ul>



<h1>Post-processing</h1>

<p>Elsa will perform various post-processing on request.

<p> Tracing flag "printHierarchies" will print inheritance
hierarchies in Dot format. Interesting in that virtual inheritance is
represented properly; for example <a href="in/std/3.4.5.cc">in/std/3.4.5.cc</a>
yields <a href="gendoc/3.4.5.png">3.4.5.png</a>.

<p> Tracing flag "prettyPrint" will print out the AST as C++. This is
still somewhat incomplete.  <b> Maybe say something here about how
this can be used an an extension to do source to source translation
the way oink/cc_qual infers dataflow annotations and then prints them
out again; this is worth mentioning as it is a requested feature</b>

<p><b>Maybe I should point out that in oink you can print out the
control flow graph as a dot file as well; oink will also soon contain
a way to print the data flow graph at both the expression and the
type-component granularities.</b>

<h1>Extending</h1>

<p><b>Say something here about how to extend Elsa.</b>

<p>Elsa was designed to be extended with various backends, such as
program analysis tools; One might easily extend it to be a compiler.
<b>Not to self-advertise, but it might be helpful to mention Oink here
and any other extensions you know about</b>

</body>
</html>
